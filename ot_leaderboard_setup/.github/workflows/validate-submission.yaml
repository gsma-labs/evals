name: Validate Leaderboard Submission

on:
  pull_request:
    types: [opened, synchronize, reopened]
    paths:
      - 'model_cards/**'
      - 'trajectories/**'

jobs:
  validate:
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      contents: read

    outputs:
      validation_passed: ${{ steps.set-output.outputs.passed }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install pandas pyarrow datasets huggingface_hub

      - name: Get changed files
        id: changed-files
        uses: tj-actions/changed-files@v44
        with:
          files: |
            model_cards/**
            trajectories/**

      - name: Validate submission
        id: validate
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          python .github/scripts/validate_submission.py \
            --files "${{ steps.changed-files.outputs.all_changed_files }}"
        continue-on-error: true

      - name: Post validation results
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            let validation;
            try {
              validation = JSON.parse(fs.readFileSync('validation_result.json', 'utf8'));
            } catch (e) {
              validation = {
                passed: false,
                errors: ['Validation script failed to produce results'],
                checks: {},
                sample_details: {}
              };
            }

            let body = '## Submission Validation Results\n\n';

            if (validation.passed) {
              body += ':white_check_mark: **All validations passed!**\n\n';
              body += 'A maintainer will review your submission shortly.\n\n';
            } else {
              body += ':x: **Validation failed**\n\n';
              if (validation.errors && validation.errors.length > 0) {
                body += '### Errors:\n';
                for (const error of validation.errors) {
                  body += `- ${error}\n`;
                }
                body += '\n';
              }
            }

            body += '### Checklist:\n';
            const checks = validation.checks || {};
            body += `- [${checks.parquet_exists ? 'x' : ' '}] Parquet file exists\n`;
            body += `- [${checks.parquet_schema ? 'x' : ' '}] Parquet has required columns\n`;
            body += `- [${checks.json_valid ? 'x' : ' '}] JSON trajectory files are valid\n`;
            body += `- [${checks.model_format ? 'x' : ' '}] Model field matches expected format\n`;
            body += `- [${checks.provider_recognized ? 'x' : ' '}] Provider is recognized\n`;
            body += `- [${checks.inspect_eval ? 'x' : ' '}] Evaluation done using Inspect\n`;
            body += `- [${checks.no_errors ? 'x' : ' '}] No errors in trajectory logs\n`;
            body += `- [${checks.sample_count_valid ? 'x' : ' '}] Sample counts match expected (no --limit)\n`;

            if (validation.sample_details && Object.keys(validation.sample_details).length > 0) {
              body += '\n### Sample Count Details:\n';
              for (const [benchmark, detail] of Object.entries(validation.sample_details)) {
                const icon = detail.valid ? ':white_check_mark:' : ':x:';
                const expected = detail.expected === 'unknown' ? '?' : detail.expected;
                const skipped = detail.skipped ? ' *(validation skipped)*' : '';
                body += `- ${icon} **${benchmark}**: ${detail.actual} / ${expected} samples${skipped}\n`;
              }
            }

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

      - name: Set output
        id: set-output
        run: |
          if [ -f validation_result.json ]; then
            PASSED=$(python3 -c "import json; print(str(json.load(open('validation_result.json'))['passed']))")
            echo "passed=$PASSED" >> $GITHUB_OUTPUT
          else
            echo "passed=False" >> $GITHUB_OUTPUT
          fi

      - name: Fail if validation failed
        if: steps.validate.outcome == 'failure'
        run: exit 1

  on-validation-pass:
    runs-on: ubuntu-latest
    needs: validate
    if: needs.validate.outputs.validation_passed == 'True'
    permissions:
      pull-requests: write

    steps:
      - name: Request review from maintainer
        uses: actions/github-script@v7
        with:
          script: |
            const prNumber = context.issue.number;

            // Add ready-for-review label
            await github.rest.issues.addLabels({
              issue_number: prNumber,
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: ['submission', 'ready-for-review']
            });

            // Remove needs-work label if present
            try {
              await github.rest.issues.removeLabel({
                issue_number: prNumber,
                owner: context.repo.owner,
                repo: context.repo.repo,
                name: 'needs-work'
              });
            } catch (e) {
              // Label may not exist, ignore
            }

            // Request review from @eaguaida
            try {
              await github.rest.pulls.requestReviewers({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: prNumber,
                reviewers: ['eaguaida']
              });
            } catch (e) {
              console.log('Could not request review:', e.message);
            }

  on-validation-fail:
    runs-on: ubuntu-latest
    needs: validate
    if: needs.validate.outputs.validation_passed == 'False'
    permissions:
      pull-requests: write

    steps:
      - name: Add needs-work label
        uses: actions/github-script@v7
        with:
          script: |
            const prNumber = context.issue.number;

            // Add needs-work label
            await github.rest.issues.addLabels({
              issue_number: prNumber,
              owner: context.repo.owner,
              repo: context.repo.repo,
              labels: ['submission', 'needs-work']
            });

            // Remove ready-for-review label if present
            try {
              await github.rest.issues.removeLabel({
                issue_number: prNumber,
                owner: context.repo.owner,
                repo: context.repo.repo,
                name: 'ready-for-review'
              });
            } catch (e) {
              // Label may not exist, ignore
            }
